{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data.pkl')\n",
    "data = data[[\n",
    "    'date_block_num',\n",
    "    'shop_id',\n",
    "    'item_id',\n",
    "    'item_cnt_month',\n",
    "    #'city_code',\n",
    "    'item_category_id',\n",
    "    'type_code',\n",
    "    'subtype_code',\n",
    "    'item_cnt_month_lag_1',\n",
    "    'item_cnt_month_lag_2',\n",
    "    'item_cnt_month_lag_3',\n",
    "    'item_cnt_month_lag_6',\n",
    "    'item_cnt_month_lag_12',\n",
    "    'date_avg_item_cnt_lag_1',\n",
    "    'date_item_avg_item_cnt_lag_1',\n",
    "    'date_item_avg_item_cnt_lag_2',\n",
    "    'date_item_avg_item_cnt_lag_3',\n",
    "    'date_item_avg_item_cnt_lag_6',\n",
    "    #'date_item_avg_item_cnt_lag_12',\n",
    "    'date_shop_avg_item_cnt_lag_1',\n",
    "    'date_shop_avg_item_cnt_lag_2',\n",
    "    'date_shop_avg_item_cnt_lag_3',\n",
    "    'date_shop_avg_item_cnt_lag_6',\n",
    "    #'date_shop_avg_item_cnt_lag_12',\n",
    "    'date_cat_avg_item_cnt_lag_1',\n",
    "    'date_shop_cat_avg_item_cnt_lag_1',\n",
    "    #'date_shop_type_avg_item_cnt_lag_1',\n",
    "    #'date_shop_subtype_avg_item_cnt_lag_1',\n",
    "    'date_city_avg_item_cnt_lag_1',\n",
    "    'date_item_city_avg_item_cnt_lag_1',\n",
    "    #'date_type_avg_item_cnt_lag_1',\n",
    "    #'date_subtype_avg_item_cnt_lag_1',\n",
    "    'delta_price_lag',\n",
    "    'month',\n",
    "    #'days',\n",
    "    'item_shop_last_sale',\n",
    "    'item_last_sale',\n",
    "    'item_shop_first_sale',\n",
    "    'item_first_sale',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
    "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def writeFile(predic):\n",
    "    with open('output.csv', 'w', newline='') as csvfile:\n",
    "      # 建立 CSV 檔寫入器\n",
    "      writer = csv.writer(csvfile)\n",
    "\n",
    "      # 寫入一列資料\n",
    "      writer.writerow(['ID','item_cnt_month'])\n",
    "      index = 0  \n",
    "      for data in predic:\n",
    "          writer.writerow([str(index),str(data)])\n",
    "          index+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45105982  0.35654303  1.1428175  ... -0.00669518  0.10681294\n",
      "  0.03615908]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "to_be_predicted = np.array(X_test)\n",
    "predicted_sales = lm.predict(to_be_predicted)\n",
    "\n",
    "print(predicted_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeFile(list(np.maximum(np.array(predicted_sales+0.11), 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56105983 0.46654302 1.2528175  ... 0.10330482 0.21681294 0.14615908]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_sales+0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186922 samples, validate on 238172 samples\n",
      "Epoch 1/10\n",
      " - 189s - loss: 1.4110 - val_loss: 1.2894\n",
      "Epoch 2/10\n",
      " - 194s - loss: 1.4084 - val_loss: 1.2618\n",
      "Epoch 3/10\n",
      " - 190s - loss: 1.2758 - val_loss: 1.1771\n",
      "Epoch 4/10\n",
      " - 191s - loss: 1.2376 - val_loss: 1.2270\n",
      "Epoch 5/10\n",
      " - 192s - loss: 1.1866 - val_loss: 1.0984\n",
      "Epoch 6/10\n",
      " - 192s - loss: 1.1384 - val_loss: 1.0847\n",
      "Epoch 7/10\n",
      " - 192s - loss: 1.1486 - val_loss: 1.0923\n",
      "Epoch 8/10\n",
      " - 195s - loss: 1.1167 - val_loss: 1.1132\n",
      "Epoch 9/10\n",
      " - 191s - loss: 1.0759 - val_loss: 1.1325\n",
      "Epoch 10/10\n",
      " - 191s - loss: 1.0606 - val_loss: 1.0792\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(30,), kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(128, kernel_initializer='normal', activation='softmax'))\n",
    "model.add(Dense(32,kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(16,kernel_initializer='normal', activation='softmax'))\n",
    "model.add(Dense(1,kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam') \n",
    "\n",
    "train_history = model.fit(x=X_train, y=Y_train, validation_data=([X_valid,Y_valid]), epochs=30, batch_size=1000, verbose=2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186922 samples, validate on 238172 samples\n",
      "Epoch 1/10\n",
      " - 766s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 2/10\n",
      " - 766s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 3/10\n",
      " - 701s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 4/10\n",
      " - 698s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 5/10\n",
      " - 697s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 6/10\n",
      " - 696s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 7/10\n",
      " - 696s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 8/10\n",
      " - 694s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 9/10\n",
      " - 691s - loss: 1.4954 - val_loss: 1.3577\n",
      "Epoch 10/10\n",
      " - 694s - loss: 1.4954 - val_loss: 1.3577\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model_lstm = Sequential()\n",
    "\n",
    "model_lstm.add(layers.RepeatVector(3))\n",
    "model_lstm.add(Dense(256,kernel_initializer='normal', activation='relu'))\n",
    "model_lstm.add(LSTM(256, return_sequences=True))\n",
    "model_lstm.add(Flatten())\n",
    "model_lstm.add(Dense(256,kernel_initializer='normal', activation='relu'))\n",
    "model_lstm.add(Dense(1,kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model_lstm.compile(loss='mse', optimizer='adam') \n",
    "\n",
    "train_history = model_lstm.fit(x=np.array(X_train), y=np.array(Y_train), validation_data=([np.array(X_valid),np.array(Y_valid)]), epochs=10, batch_size=1000, verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "repeat_vector_15 (RepeatVect (None, 3, 30)             0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3, 256)            7936      \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 3, 256)            525312    \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 730,369\n",
      "Trainable params: 730,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
